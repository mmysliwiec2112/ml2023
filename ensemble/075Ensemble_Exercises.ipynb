{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble methods. Exercises\n",
    "\n",
    "\n",
    "In this section we have only two exercise:\n",
    "\n",
    "1. Find the best three classifier in the stacking method using the classifiers from scikit-learn package.\n",
    "\n",
    "2. Build arcing arc-x4 method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r data_set\n",
    "%store -r labels\n",
    "%store -r test_data_set\n",
    "%store -r test_labels\n",
    "%store -r unique_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Find the best three classifier in the stacking method\n",
    "\n",
    "Please use the following classifiers:\n",
    "\n",
    "* Linear regression,\n",
    "* Nearest Neighbors,\n",
    "* Linear SVM,\n",
    "* Decision Tree,\n",
    "* Naive Bayes,\n",
    "* QDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_classifiers():\n",
    "    lreg = LinearRegression()\n",
    "    lreg.fit(data_set, labels)\n",
    "\n",
    "    knn = KNeighborsClassifier()\n",
    "    knn.fit(data_set, labels)\n",
    "\n",
    "    svc = SVC()\n",
    "    svc.fit(data_set,labels)\n",
    "\n",
    "    dt = DecisionTreeClassifier()\n",
    "    dt.fit(data_set,labels)\n",
    "\n",
    "    nb = GaussianNB()\n",
    "    nb.fit(data_set,labels)\n",
    "\n",
    "    qda = QuadraticDiscriminantAnalysis()\n",
    "    qda.fit(data_set,labels)\n",
    "\n",
    "    return lreg, knn, svc, dt, nb, qda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def calculate_accuracy_vector(predicted, labels):\n",
    "    result = []\n",
    "    for i in range(len(predicted)):\n",
    "        if predicted[i] == labels[i]:\n",
    "            result.append(1)\n",
    "        else:\n",
    "            result.append(0)\n",
    "    return result\n",
    "\n",
    "def build_grading_classifier(classifiers):\n",
    "    output = []\n",
    "    matrix = []\n",
    "    for classifier in classifiers:\n",
    "        predicted = classifier.predict(data_set)\n",
    "        output.append(predicted)\n",
    "        matrix.append(calculate_accuracy_vector(predicted,labels))\n",
    "\n",
    "    grading_classifiers = []\n",
    "    for i in range(len(classifiers)):\n",
    "        tree = DecisionTreeClassifier()\n",
    "        tree.fit(data_set, matrix[i])\n",
    "        grading_classifiers.append(tree)\n",
    "    return grading_classifiers\n",
    "\n",
    "def test_prediction(classifiers, grading_classifiers, i):\n",
    "    prediction = classifiers[i].predict(test_data_set)\n",
    "    grad = grading_classifiers[i].predict(test_data_set)\n",
    "    return prediction, grad\n",
    "\n",
    "classifiers = test_classifiers()\n",
    "grading_classifiers = build_grading_classifier(classifiers)\n",
    "names = ['lreg', 'knn', 'svc', 'dt', 'nb', 'qda']\n",
    "sums_grad = []\n",
    "for i in range(len(classifiers)):\n",
    "    prediction, grad = test_prediction(classifiers, grading_classifiers, i)\n",
    "    # print(f'scores for the {names[i]} model: {prediction}\\n{grad}\\n{test_labels}\\nsum of scores:{sum(grad)}')\n",
    "    sums_grad.append(sum(grad))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.bar(names, sums_grad)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def build_classifiers():\n",
    "    knn = KNeighborsClassifier()\n",
    "    knn.fit(data_set, labels)\n",
    "\n",
    "    dt = DecisionTreeClassifier()\n",
    "    dt.fit(data_set,labels)\n",
    "\n",
    "    svc = SVC()\n",
    "    svc.fit(data_set, labels)\n",
    "\n",
    "    return knn, dt, svc\n",
    "# lreg, qda, svc,"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_stacked_classifier(classifiers, stacked_classifier):\n",
    "    output = []\n",
    "    # print(classifiers)\n",
    "    for classifier in classifiers:\n",
    "        output.append(classifier.predict(data_set))\n",
    "    output = np.array(output).reshape((130,3))\n",
    "    \n",
    "    # stacked classifier part:\n",
    "    # stacked_classifier = SVC()\n",
    "    stacked_classifier.fit(output.reshape((130,3)), labels.reshape((130,)))\n",
    "    test_set = []\n",
    "    for classifier in classifiers:\n",
    "        test_set.append(classifier.predict(test_data_set))\n",
    "    test_set = np.array(test_set).reshape((len(test_set[0]),3))\n",
    "    predicted = stacked_classifier.predict(test_set)\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n",
      "0.1\n",
      "0.0\n",
      "0.15\n",
      "1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\ml\\lib\\site-packages\\sklearn\\discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    }
   ],
   "source": [
    "classifiers = build_classifiers()\n",
    "lreg = LinearRegression()\n",
    "qda = QuadraticDiscriminantAnalysis()\n",
    "svc = SVC()\n",
    "knn = KNeighborsClassifier()\n",
    "dt = DecisionTreeClassifier()\n",
    "nb = GaussianNB()\n",
    "for meta_classifier in [qda, svc, knn, dt, nb]:\n",
    "    predicted = build_stacked_classifier(classifiers, meta_classifier)\n",
    "    accuracy = accuracy_score(test_labels, predicted)\n",
    "    print(accuracy)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# prepare data set\n",
    "\n",
    "def generate_data(sample_number, feature_number, label_number):\n",
    "    data_set = np.random.random_sample((sample_number, feature_number))\n",
    "    labels = np.random.choice(label_number, sample_number)\n",
    "    return data_set, labels\n",
    "\n",
    "# labels = 2\n",
    "dimension = 2\n",
    "test_set_size = 1000\n",
    "train_set_size = 5000\n",
    "train_set, train_labels = generate_data(train_set_size, dimension, labels)\n",
    "test_set, test_labels = generate_data(test_set_size, dimension, labels)\n",
    "\n",
    "# init weights\n",
    "# number_of_iterations = 10\n",
    "# weights = np.ones((test_set_size,)) / test_set_size\n",
    "\n",
    "def calculate_accuracy_vector(predicted, labels):\n",
    "    result = []\n",
    "    for i in range(len(predicted)):\n",
    "        if predicted[i] == labels[i]:\n",
    "            result.append(0)\n",
    "        else:\n",
    "            result.append(1)\n",
    "    return result\n",
    "\n",
    "def train_model(classifier, weights):\n",
    "    return classifier.fit(X=test_set, y=test_labels, sample_weight=weights)\n",
    "\n",
    "def calculate_error(model):\n",
    "    predicted = model.predict(test_set)\n",
    "    I=calculate_accuracy_vector(predicted, test_labels)\n",
    "    Z=np.sum(I)\n",
    "    return (1+Z)/1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill the two functions below:"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Exercise 2:\n",
    "\n",
    "Use the boosting method and change the code to fullfilt the following requirements:\n",
    "\n",
    "* the weights should be calculated as:\n",
    "$w_{n}^{(t+1)}=\\frac{1+ I(y_{n}\\neq h_{t}(x_{n}))}{\\sum_{i=1}^{N}1+I(y_{i}\\neq h_{t}(x_{i}))}$,\n",
    "* the prediction is done with a voting method."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_new_weights(model):\n",
    "    results = np.array(calculate_accuracy_vector(model.predict(test_set), test_labels))\n",
    "    new_weights = (1 + results) / (sum([result for result in results]) * 1.0)\n",
    "    return new_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the classifier with the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
      " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
      " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
      " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
      " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
      " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
      " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
      " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
      " 0.001 0.001 0.001 0.001]\n",
      "[0.0033389  0.0033389  0.0033389  0.0033389  0.00166945 0.0033389\n",
      " 0.00166945 0.0033389  0.00166945 0.0033389  0.0033389  0.00166945\n",
      " 0.0033389  0.0033389  0.0033389  0.0033389  0.0033389  0.0033389\n",
      " 0.0033389  0.0033389  0.0033389  0.00166945 0.00166945 0.0033389\n",
      " 0.00166945 0.0033389  0.0033389  0.00166945 0.0033389  0.0033389\n",
      " 0.0033389  0.0033389  0.0033389  0.0033389  0.00166945 0.00166945\n",
      " 0.0033389  0.0033389  0.00166945 0.0033389  0.00166945 0.0033389\n",
      " 0.00166945 0.0033389  0.00166945 0.00166945 0.0033389  0.00166945\n",
      " 0.00166945 0.0033389  0.0033389  0.0033389  0.0033389  0.00166945\n",
      " 0.0033389  0.0033389  0.00166945 0.0033389  0.0033389  0.0033389\n",
      " 0.0033389  0.0033389  0.00166945 0.00166945 0.00166945 0.00166945\n",
      " 0.0033389  0.0033389  0.0033389  0.0033389  0.00166945 0.00166945\n",
      " 0.00166945 0.0033389  0.0033389  0.00166945 0.0033389  0.00166945\n",
      " 0.0033389  0.00166945 0.0033389  0.00166945 0.0033389  0.0033389\n",
      " 0.00166945 0.0033389  0.00166945 0.00166945 0.0033389  0.0033389\n",
      " 0.00166945 0.0033389  0.00166945 0.00166945 0.00166945 0.0033389\n",
      " 0.0033389  0.0033389  0.0033389  0.0033389 ]\n",
      "[0.00157729 0.00157729 0.00157729 0.00157729 0.00315457 0.00315457\n",
      " 0.00315457 0.00315457 0.00315457 0.00157729 0.00157729 0.00315457\n",
      " 0.00315457 0.00315457 0.00157729 0.00157729 0.00157729 0.00315457\n",
      " 0.00157729 0.00157729 0.00315457 0.00315457 0.00315457 0.00315457\n",
      " 0.00315457 0.00315457 0.00315457 0.00315457 0.00315457 0.00157729\n",
      " 0.00315457 0.00157729 0.00157729 0.00157729 0.00315457 0.00315457\n",
      " 0.00157729 0.00315457 0.00315457 0.00157729 0.00315457 0.00315457\n",
      " 0.00315457 0.00315457 0.00315457 0.00315457 0.00157729 0.00315457\n",
      " 0.00315457 0.00157729 0.00315457 0.00315457 0.00157729 0.00315457\n",
      " 0.00315457 0.00157729 0.00315457 0.00315457 0.00157729 0.00157729\n",
      " 0.00315457 0.00157729 0.00315457 0.00315457 0.00315457 0.00157729\n",
      " 0.00315457 0.00315457 0.00157729 0.00157729 0.00315457 0.00315457\n",
      " 0.00315457 0.00315457 0.00315457 0.00315457 0.00315457 0.00315457\n",
      " 0.00315457 0.00315457 0.00157729 0.00315457 0.00157729 0.00157729\n",
      " 0.00315457 0.00157729 0.00315457 0.00315457 0.00157729 0.00315457\n",
      " 0.00315457 0.00157729 0.00315457 0.00315457 0.00315457 0.00157729\n",
      " 0.00315457 0.00315457 0.00157729 0.00157729]\n",
      "[0.0033389  0.0033389  0.0033389  0.0033389  0.00166945 0.0033389\n",
      " 0.00166945 0.0033389  0.00166945 0.0033389  0.0033389  0.00166945\n",
      " 0.0033389  0.0033389  0.0033389  0.0033389  0.0033389  0.0033389\n",
      " 0.0033389  0.0033389  0.0033389  0.00166945 0.00166945 0.0033389\n",
      " 0.00166945 0.0033389  0.0033389  0.00166945 0.0033389  0.0033389\n",
      " 0.0033389  0.0033389  0.0033389  0.0033389  0.00166945 0.00166945\n",
      " 0.0033389  0.0033389  0.00166945 0.0033389  0.00166945 0.0033389\n",
      " 0.00166945 0.0033389  0.00166945 0.00166945 0.0033389  0.00166945\n",
      " 0.00166945 0.0033389  0.0033389  0.0033389  0.0033389  0.00166945\n",
      " 0.0033389  0.0033389  0.00166945 0.0033389  0.0033389  0.0033389\n",
      " 0.0033389  0.0033389  0.00166945 0.00166945 0.00166945 0.00166945\n",
      " 0.0033389  0.0033389  0.0033389  0.0033389  0.00166945 0.00166945\n",
      " 0.00166945 0.0033389  0.0033389  0.00166945 0.0033389  0.00166945\n",
      " 0.0033389  0.00166945 0.0033389  0.00166945 0.0033389  0.0033389\n",
      " 0.00166945 0.0033389  0.00166945 0.00166945 0.0033389  0.0033389\n",
      " 0.00166945 0.0033389  0.00166945 0.00166945 0.00166945 0.0033389\n",
      " 0.0033389  0.0033389  0.0033389  0.0033389 ]\n",
      "[0.00157729 0.00157729 0.00157729 0.00157729 0.00315457 0.00315457\n",
      " 0.00315457 0.00315457 0.00315457 0.00157729 0.00157729 0.00315457\n",
      " 0.00315457 0.00315457 0.00157729 0.00157729 0.00157729 0.00315457\n",
      " 0.00157729 0.00157729 0.00315457 0.00315457 0.00315457 0.00315457\n",
      " 0.00315457 0.00315457 0.00315457 0.00315457 0.00315457 0.00157729\n",
      " 0.00315457 0.00157729 0.00157729 0.00157729 0.00315457 0.00315457\n",
      " 0.00157729 0.00315457 0.00315457 0.00157729 0.00315457 0.00315457\n",
      " 0.00315457 0.00315457 0.00315457 0.00315457 0.00157729 0.00315457\n",
      " 0.00315457 0.00157729 0.00315457 0.00315457 0.00157729 0.00315457\n",
      " 0.00315457 0.00157729 0.00315457 0.00315457 0.00157729 0.00157729\n",
      " 0.00315457 0.00157729 0.00315457 0.00315457 0.00315457 0.00157729\n",
      " 0.00315457 0.00315457 0.00157729 0.00157729 0.00315457 0.00315457\n",
      " 0.00315457 0.00315457 0.00315457 0.00315457 0.00315457 0.00315457\n",
      " 0.00315457 0.00315457 0.00157729 0.00315457 0.00157729 0.00157729\n",
      " 0.00315457 0.00157729 0.00315457 0.00315457 0.00157729 0.00315457\n",
      " 0.00315457 0.00157729 0.00315457 0.00315457 0.00315457 0.00157729\n",
      " 0.00315457 0.00315457 0.00157729 0.00157729]\n",
      "[0.0033389  0.0033389  0.0033389  0.0033389  0.00166945 0.0033389\n",
      " 0.00166945 0.0033389  0.00166945 0.0033389  0.0033389  0.00166945\n",
      " 0.0033389  0.0033389  0.0033389  0.0033389  0.0033389  0.0033389\n",
      " 0.0033389  0.0033389  0.0033389  0.00166945 0.00166945 0.0033389\n",
      " 0.00166945 0.0033389  0.0033389  0.00166945 0.0033389  0.0033389\n",
      " 0.0033389  0.0033389  0.0033389  0.0033389  0.00166945 0.00166945\n",
      " 0.0033389  0.0033389  0.00166945 0.0033389  0.00166945 0.0033389\n",
      " 0.00166945 0.0033389  0.00166945 0.00166945 0.0033389  0.00166945\n",
      " 0.00166945 0.0033389  0.0033389  0.0033389  0.0033389  0.00166945\n",
      " 0.0033389  0.0033389  0.00166945 0.0033389  0.0033389  0.0033389\n",
      " 0.0033389  0.0033389  0.00166945 0.00166945 0.00166945 0.00166945\n",
      " 0.0033389  0.0033389  0.0033389  0.0033389  0.00166945 0.00166945\n",
      " 0.00166945 0.0033389  0.0033389  0.00166945 0.0033389  0.00166945\n",
      " 0.0033389  0.00166945 0.0033389  0.00166945 0.0033389  0.0033389\n",
      " 0.00166945 0.0033389  0.00166945 0.00166945 0.0033389  0.0033389\n",
      " 0.00166945 0.0033389  0.00166945 0.00166945 0.00166945 0.0033389\n",
      " 0.0033389  0.0033389  0.0033389  0.0033389 ]\n",
      "[0.00157729 0.00157729 0.00157729 0.00157729 0.00315457 0.00315457\n",
      " 0.00315457 0.00315457 0.00315457 0.00157729 0.00157729 0.00315457\n",
      " 0.00315457 0.00315457 0.00157729 0.00157729 0.00157729 0.00315457\n",
      " 0.00157729 0.00157729 0.00315457 0.00315457 0.00315457 0.00315457\n",
      " 0.00315457 0.00315457 0.00315457 0.00315457 0.00315457 0.00157729\n",
      " 0.00315457 0.00157729 0.00157729 0.00157729 0.00315457 0.00315457\n",
      " 0.00157729 0.00315457 0.00315457 0.00157729 0.00315457 0.00315457\n",
      " 0.00315457 0.00315457 0.00315457 0.00315457 0.00157729 0.00315457\n",
      " 0.00315457 0.00157729 0.00315457 0.00315457 0.00157729 0.00315457\n",
      " 0.00315457 0.00157729 0.00315457 0.00315457 0.00157729 0.00157729\n",
      " 0.00315457 0.00157729 0.00315457 0.00315457 0.00315457 0.00157729\n",
      " 0.00315457 0.00315457 0.00157729 0.00157729 0.00315457 0.00315457\n",
      " 0.00315457 0.00315457 0.00315457 0.00315457 0.00315457 0.00315457\n",
      " 0.00315457 0.00315457 0.00157729 0.00315457 0.00157729 0.00157729\n",
      " 0.00315457 0.00157729 0.00315457 0.00315457 0.00157729 0.00315457\n",
      " 0.00315457 0.00157729 0.00315457 0.00315457 0.00315457 0.00157729\n",
      " 0.00315457 0.00315457 0.00157729 0.00157729]\n",
      "[0.0033389  0.0033389  0.0033389  0.0033389  0.00166945 0.0033389\n",
      " 0.00166945 0.0033389  0.00166945 0.0033389  0.0033389  0.00166945\n",
      " 0.0033389  0.0033389  0.0033389  0.0033389  0.0033389  0.0033389\n",
      " 0.0033389  0.0033389  0.0033389  0.00166945 0.00166945 0.0033389\n",
      " 0.00166945 0.0033389  0.0033389  0.00166945 0.0033389  0.0033389\n",
      " 0.0033389  0.0033389  0.0033389  0.0033389  0.00166945 0.00166945\n",
      " 0.0033389  0.0033389  0.00166945 0.0033389  0.00166945 0.0033389\n",
      " 0.00166945 0.0033389  0.00166945 0.00166945 0.0033389  0.00166945\n",
      " 0.00166945 0.0033389  0.0033389  0.0033389  0.0033389  0.00166945\n",
      " 0.0033389  0.0033389  0.00166945 0.0033389  0.0033389  0.0033389\n",
      " 0.0033389  0.0033389  0.00166945 0.00166945 0.00166945 0.00166945\n",
      " 0.0033389  0.0033389  0.0033389  0.0033389  0.00166945 0.00166945\n",
      " 0.00166945 0.0033389  0.0033389  0.00166945 0.0033389  0.00166945\n",
      " 0.0033389  0.00166945 0.0033389  0.00166945 0.0033389  0.0033389\n",
      " 0.00166945 0.0033389  0.00166945 0.00166945 0.0033389  0.0033389\n",
      " 0.00166945 0.0033389  0.00166945 0.00166945 0.00166945 0.0033389\n",
      " 0.0033389  0.0033389  0.0033389  0.0033389 ]\n",
      "[0.00157729 0.00157729 0.00157729 0.00157729 0.00315457 0.00315457\n",
      " 0.00315457 0.00315457 0.00315457 0.00157729 0.00157729 0.00315457\n",
      " 0.00315457 0.00315457 0.00157729 0.00157729 0.00157729 0.00315457\n",
      " 0.00157729 0.00157729 0.00315457 0.00315457 0.00315457 0.00315457\n",
      " 0.00315457 0.00315457 0.00315457 0.00315457 0.00315457 0.00157729\n",
      " 0.00315457 0.00157729 0.00157729 0.00157729 0.00315457 0.00315457\n",
      " 0.00157729 0.00315457 0.00315457 0.00157729 0.00315457 0.00315457\n",
      " 0.00315457 0.00315457 0.00315457 0.00315457 0.00157729 0.00315457\n",
      " 0.00315457 0.00157729 0.00315457 0.00315457 0.00157729 0.00315457\n",
      " 0.00315457 0.00157729 0.00315457 0.00315457 0.00157729 0.00157729\n",
      " 0.00315457 0.00157729 0.00315457 0.00315457 0.00315457 0.00157729\n",
      " 0.00315457 0.00315457 0.00157729 0.00157729 0.00315457 0.00315457\n",
      " 0.00315457 0.00315457 0.00315457 0.00315457 0.00315457 0.00315457\n",
      " 0.00315457 0.00315457 0.00157729 0.00315457 0.00157729 0.00157729\n",
      " 0.00315457 0.00157729 0.00315457 0.00315457 0.00157729 0.00315457\n",
      " 0.00315457 0.00157729 0.00315457 0.00315457 0.00315457 0.00157729\n",
      " 0.00315457 0.00315457 0.00157729 0.00157729]\n",
      "[0.0033389  0.0033389  0.0033389  0.0033389  0.00166945 0.0033389\n",
      " 0.00166945 0.0033389  0.00166945 0.0033389  0.0033389  0.00166945\n",
      " 0.0033389  0.0033389  0.0033389  0.0033389  0.0033389  0.0033389\n",
      " 0.0033389  0.0033389  0.0033389  0.00166945 0.00166945 0.0033389\n",
      " 0.00166945 0.0033389  0.0033389  0.00166945 0.0033389  0.0033389\n",
      " 0.0033389  0.0033389  0.0033389  0.0033389  0.00166945 0.00166945\n",
      " 0.0033389  0.0033389  0.00166945 0.0033389  0.00166945 0.0033389\n",
      " 0.00166945 0.0033389  0.00166945 0.00166945 0.0033389  0.00166945\n",
      " 0.00166945 0.0033389  0.0033389  0.0033389  0.0033389  0.00166945\n",
      " 0.0033389  0.0033389  0.00166945 0.0033389  0.0033389  0.0033389\n",
      " 0.0033389  0.0033389  0.00166945 0.00166945 0.00166945 0.00166945\n",
      " 0.0033389  0.0033389  0.0033389  0.0033389  0.00166945 0.00166945\n",
      " 0.00166945 0.0033389  0.0033389  0.00166945 0.0033389  0.00166945\n",
      " 0.0033389  0.00166945 0.0033389  0.00166945 0.0033389  0.0033389\n",
      " 0.00166945 0.0033389  0.00166945 0.00166945 0.0033389  0.0033389\n",
      " 0.00166945 0.0033389  0.00166945 0.00166945 0.00166945 0.0033389\n",
      " 0.0033389  0.0033389  0.0033389  0.0033389 ]\n"
     ]
    }
   ],
   "source": [
    "classifier = DecisionTreeClassifier(max_depth=1, random_state=1)\n",
    "classifier.fit(X=train_set, y=train_labels)\n",
    "alphas = []\n",
    "classifiers = []\n",
    "number_of_iterations = 10\n",
    "weights = np.ones((test_set_size,)) / test_set_size\n",
    "for iteration in range(number_of_iterations):\n",
    "    print(weights[:100])\n",
    "    model = train_model(classifier, weights)\n",
    "    weights = set_new_weights(model)\n",
    "    classifiers.append(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the validation data set:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill the prediction code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 10)]\n",
      "[0]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def get_prediction(x):\n",
    "    predicion = [classifier.predict(x).tolist()[0] for classifier in classifiers]\n",
    "    return Counter(predicion)\n",
    "\n",
    "validate_x, validate_label = generate_data(1, dimension, 2)\n",
    "prediction = get_prediction(validate_x).most_common()\n",
    "\n",
    "print(prediction)\n",
    "print(validate_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test it:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
